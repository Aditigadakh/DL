#--Assignment 5--

# Build the Image classification model by dividing the model into following 4 stages:
# a. Loading and preprocessing the image data
# b. Defining the model’s architecture
# c. Training the model
# d. Estimating the model’s performance
# Dataset: MNIST Handwritten  




#importing required packages
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D
import matplotlib.pyplot as plt
import numpy as np

# a. laoding and preprocessing image data
mnist=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()
input_shape=(28,28,1)

#making sure that values are float so that we can get decimal points after division
x_train=x_train.reshape(x_train.shape[0], 28,28,1)
x_test=x_test.reshape(x_test.shape[0], 28,28,1)

print("Data type of x_train : " , x_train.dtype)
x_train=x_train.astype('float32')
x_test=x_test.astype('float32')
print("Datatype after converting : ", x_train.dtype)

#Normalizing the rgb codes by dividing it to the max rgb values
x_train=x_train / 255
x_test=x_test / 255

print("shape of training : ",x_train.shape)
print("shape of testing : " , x_test.shape)

# b. Defining the model architecture 
model = Sequential()
model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(200,activation="relu"))
model.add(Dropout(0,3))
model.add(Dense(10,activation="softmax"))

model.summary()

# c.training the model
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model.fit(x_train,y_train,epochs=2)


# d.estimating the models performance
test_loss,test_acc = model.evaluate(x_test,y_test)
print("Loss=%.3f" %test_loss)
print("Accuracy=%.3f" %test_acc)

#showing image at position[] from dataset: 
image=x_train[0]
plt.imshow(np.squeeze(image), cmap='gray')
plt.show()

#predicting the class of image
image=[image.reshape(1, image.shape[0], image.shape[1], image.shape[2])]
predict_model = model.predict([image])
print("Predicted Class: {}".format(np.argmax(predict_model)))







#oral

# a. laoding and preprocessing image data
mnist=tf.keras.datasets.mnist # Loads the MNIST dataset from TensorFlow/Keras, which contains grayscale images of handwritten digits.
(x_train,y_train),(x_test,y_test)=mnist.load_data() # Loads and splits the dataset into training and testing sets.
input_shape=(28,28,1) # Defines the input shape for the model, which corresponds to a 28x28 pixel image with a single channel (grayscale).

#making sure that values are float so that we can get decimal points after division
# for below lines
# x_train = x_train.reshape(x_train.shape[0], 28, 28, 1): This line reshapes the training data x_train to have dimensions (number_of_samples, 28, 28, 1). The reshaping is necessary to match the input shape expected by the convolutional layer of the neural network. The 1 at the end indicates that each image is a single-channel (grayscale) image.
# x_test = x_test.reshape(x_test.shape[0], 28, 28, 1): Similarly, this line reshapes the testing data x_test to the same dimensions as the training data.
# print("Data type of x_train : " , x_train.dtype): This line prints the data type of the training data before any conversions. The data type is checked to ensure that it matches the expectations for further processing.
# x_train = x_train.astype('float32'): It converts the data type of x_train to float32. Neural networks often work with floating-point values, and this line ensures that the data type is appropriate for the subsequent calculations.
# x_test = x_test.astype('float32'): Similar to the previous line, it converts the data type of x_test to float32.
# print("Datatype after converting : ", x_train.dtype): After the conversion, this line prints the data type of the training data again to confirm that it is now of type float32.
# x_train = x_train / 255: This line normalizes the pixel values of the training data by dividing them by 255. Normalization scales the pixel values to be in the range [0, 1], which is a common practice in deep learning to improve the convergence of the model during training.
# x_test = x_test / 255: Similarly, it normalizes the pixel values of the testing data.
# print("shape of training : ", x_train.shape): This line prints the shape of the training data to confirm the reshaping and normalization operations. It should show the shape as (number_of_samples, 28, 28, 1).
# print("shape of testing : " , x_test.shape): Likewise, it prints the shape of the testing data, which should match the shape of the training data after preprocessing.

# # b. Defining the model architecture
# model = Sequential(): Creates a Sequential model to which you can add layers.
# The model architecture is defined as follows:
# Conv2D(28, kernel_size=(3,3), input_shape=input_shape): A convolutional layer with 28 filters and a kernel size of (3,3), accepting input with the specified shape.
# MaxPooling2D(pool_size=(2,2)): A max-pooling layer to down-sample the data.
# Flatten(): A flattening layer to convert the 2D data to a 1D vector.
# Dense(200, activation="relu"): A fully connected (dense) layer with 200 neurons and ReLU activation.
# Dropout(0.3): A dropout layer with a 30% dropout rate, which helps prevent overfitting.
# Dense(10, activation="softmax"): The output layer with 10 neurons and a softmax activation for multi-class classification.


model.summary() # Prints a summary of the model's architecture, showing the structure of the layers, the number of parameters, and the output shapes.

# c.training the model
# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']): Compiles the model by specifying the optimization algorithm ('adam'), the loss function ('sparse_categorical_crossentropy') suitable for classification, and the evaluation metric ('accuracy').

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']) #
model.fit(x_train,y_train,epochs=2) #


# d.estimating the models performance
# model.fit(x_train, y_train, epochs=2): Trains the model on the training data for 2 epochs. The model learns to make predictions and adjusts its parameters to minimize the defined loss function.


#showing image at position[] from dataset:
image = x_train[0] # Selects the first image from the training dataset.
plt.imshow(np.squeeze(image), cmap='gray') # Displays the image using Matplotlib. np.squeeze is used to remove the single-channel dimension, and cmap='gray' indicates a grayscale color map.
plt.show() # Shows the image.

